{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mining words from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.functions import array_contains\n",
    "import unicodedata\n",
    "import pycountry\n",
    "import string\n",
    "from operator import add\n",
    "import spacy\n",
    "import os\n",
    "import time\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Analysing Wikipedia\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(\"./nowiki-20210111-cirrussearch-content.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the schema just to explore the dataset. Found [a description of the JSON dump format on Wikipedia](https://meta.wikimedia.org/wiki/Data_dumps/Misc_dumps_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- auxiliary_text: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- category: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- content_model: string (nullable = true)\n",
      " |-- coordinates: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- coord: struct (nullable = true)\n",
      " |    |    |    |-- lat: double (nullable = true)\n",
      " |    |    |    |-- lon: double (nullable = true)\n",
      " |    |    |-- country: string (nullable = true)\n",
      " |    |    |-- dim: long (nullable = true)\n",
      " |    |    |-- globe: string (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- primary: boolean (nullable = true)\n",
      " |    |    |-- region: string (nullable = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |-- create_timestamp: string (nullable = true)\n",
      " |-- defaultsort: string (nullable = true)\n",
      " |-- display_title: string (nullable = true)\n",
      " |-- external_link: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- heading: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- incoming_links: long (nullable = true)\n",
      " |-- index: struct (nullable = true)\n",
      " |    |-- _id: string (nullable = true)\n",
      " |    |-- _type: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- namespace: long (nullable = true)\n",
      " |-- namespace_text: string (nullable = true)\n",
      " |-- opening_text: string (nullable = true)\n",
      " |-- ores_articletopic: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ores_articletopics: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- outgoing_link: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- popularity_score: double (nullable = true)\n",
      " |-- redirect: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- namespace: long (nullable = true)\n",
      " |    |    |-- title: string (nullable = true)\n",
      " |-- score: double (nullable = true)\n",
      " |-- source_text: string (nullable = true)\n",
      " |-- template: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- text_bytes: long (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- version: long (nullable = true)\n",
      " |-- version_type: string (nullable = true)\n",
      " |-- wiki: string (nullable = true)\n",
      " |-- wikibase_item: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------+--------------------+--------------------+----------------+-------------+--------------------+--------------------+--------------+--------------+--------+---------+--------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------+------------+------+-------------+\n",
      "|      auxiliary_text|            category|content_model|         coordinates|    create_timestamp|     defaultsort|display_title|       external_link|             heading|incoming_links|         index|language|namespace|namespace_text|        opening_text|   ores_articletopic|  ores_articletopics|       outgoing_link|    popularity_score|            redirect|             score|         source_text|            template|                text|text_bytes|           timestamp|               title| version|version_type|  wiki|wikibase_item|\n",
      "+--------------------+--------------------+-------------+--------------------+--------------------+----------------+-------------+--------------------+--------------------+--------------+--------------+--------+---------+--------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------+------------+------+-------------+\n",
      "|                null|                null|         null|                null|                null|            null|         null|                null|                null|          null|[796279, page]|    null|     null|          null|                null|                null|                null|                null|                null|                null|              null|                null|                null|                null|      null|                null|                null|    null|        null|  null|         null|\n",
      "|[Hundene i Riga o...|[Artikler med fil...|     wikitext|                  []|2010-06-27T18:30:01Z|           false|         null|[https://www.wiki...|[Handling, Rollel...|            10|          null|      nb|        0|              |Hundene i Riga er...|                null|                null|[Björn_Kjellman, ...|1.186194065204198...|[[0, Hundarna i R...|              null|{{Kursiv tittel}}...|[Mal:Kursiv titte...|Hundene i Riga er...|      3673|2019-04-23T10:14:01Z|Hundene i Riga (f...|19391640|    external|nowiki|    Q10527170|\n",
      "|                null|                null|         null|                null|                null|            null|         null|                null|                null|          null|[296742, page]|    null|     null|          null|                null|                null|                null|                null|                null|                null|              null|                null|                null|                null|      null|                null|                null|    null|        null|  null|         null|\n",
      "|[Kill Buljo Gener...|[Artikler med død...|     wikitext|                  []|2007-03-18T20:54:18Z|           false|         null|[http://film.medi...|[Rolleliste, Anme...|            34|          null|      nb|        0|              |Kill Buljo er en ...|[Culture.Media.Fi...|[Culture.Media.Fi...|[Wikipedia:Stilma...|1.171366639389145...|[[0, Kill buljo],...|              null|{{Kursiv tittel}}...|[Mal:Kursiv titte...|Kill Buljo er en ...|      3521|2020-04-02T11:05:31Z|          Kill Buljo|20332756|    external|nowiki|     Q1741317|\n",
      "|                null|                null|         null|                null|                null|            null|         null|                null|                null|          null|[354927, page]|    null|     null|          null|                null|                null|                null|                null|                null|                null|              null|                null|                null|                null|      null|                null|                null|    null|        null|  null|         null|\n",
      "|[«Bro, bro brille...|[Sangleker, Julel...|     wikitext|                  []|2007-07-25T08:52:41Z|           false|         null|[http://www.rimog...|[Mange navn og ma...|            17|          null|      nb|        0|              |Bro, bro brille e...|                null|                null|[1014, 1957, Alli...|8.260788530815613E-6|[[0, Bro bro bril...|1.1926010434961E-5|<!--[[Fil:Nagasak...|                  []|Bro, bro brille e...|     12266|2019-01-09T10:10:54Z|     Bro, bro brille|19090815|    external|nowiki|      Q468404|\n",
      "|                null|                null|         null|                null|                null|            null|         null|                null|                null|          null|[297525, page]|    null|     null|          null|                null|                null|                null|                null|                null|                null|              null|                null|                null|                null|      null|                null|                null|    null|        null|  null|         null|\n",
      "|[Marcus Furius Ca...|[Sider med refera...|     wikitext|                  []|2007-03-20T12:55:14Z|           false|         null|[https://d-nb.inf...|                  []|             9|          null|      nb|        0|              |Marcus Furius Cam...|[Culture.Biograph...|[Culture.Biograph...|[365_f.Kr., 387_f...|7.727424079410719E-7|[[0, Marcus Furiu...|              null|{{infoboks biogra...|[Mal:Infoboks bio...|Marcus Furius Cam...|      1155|2019-09-18T23:56:53Z|Marcus Furius Cam...|19798658|    external|nowiki|      Q294862|\n",
      "|                null|                null|         null|                null|                null|            null|         null|                null|                null|          null|[357417, page]|    null|     null|          null|                null|                null|                null|                null|                null|                null|              null|                null|                null|                null|      null|                null|                null|    null|        null|  null|         null|\n",
      "|[Final Fantasy II...|[Artikler med spi...|     wikitext|                  []|2007-08-01T13:14:37Z|Final Fantasy 03|         null|[https://www.wiki...|                  []|            40|          null|      nb|        0|              |Final Fantasy III...|[Culture.Media.Vi...|[Culture.Media.Vi...|[Wikipedia:Stilma...|7.080675883556239E-7|        [[0, Ffiii]]|              null|{{Infoboks videos...|[Mal:Infoboks vid...|Final Fantasy III...|      2087|2016-04-11T18:17:25Z|   Final Fantasy III|16188033|    external|nowiki|      Q687559|\n",
      "|                null|                null|         null|                null|                null|            null|         null|                null|                null|          null|[933887, page]|    null|     null|          null|                null|                null|                null|                null|                null|                null|              null|                null|                null|                null|      null|                null|                null|    null|        null|  null|         null|\n",
      "|[Biskoppelig samf...|[Andorransk polit...|     wikitext|                  []|2011-06-29T17:29:43Z|           false|         null|[http://www.copri...|                  []|            71|          null|      nb|        0|              |Liste over samfyr...|[Culture.Biograph...|[Culture.Biograph...|[1278, 1293, 1295...|7.867417648395821E-7|[[0, Samfyrste av...|5.2176295652954E-7|'''Liste over sam...|                  []|Liste over samfyr...|     13272|2018-07-05T23:06:42Z|Liste over samfyr...|18674391|    external|nowiki|    Q16021008|\n",
      "|                null|                null|         null|                null|                null|            null|         null|                null|                null|          null|[193846, page]|    null|     null|          null|                null|                null|                null|                null|                null|                null|              null|                null|                null|                null|      null|                null|                null|    null|        null|  null|         null|\n",
      "|[Kristiansand kat...|[Artikler med død...|     wikitext|[[[58.16, 8.01027...|2006-09-20T14:53:58Z|           false|         null|[http://www.dagbl...|[Historie, Kunsts...|           128|          null|      nb|        0|              |Kristiansand kate...|[Geography.Region...|[Geography.Region...|[Norge, 1492, 164...|3.929267840988906E-6|[[0, Kristiansand...|              null|{{Infoboks skole\n",
      "...|[Mal:Infoboks sko...|Kristiansand kate...|      8272|2020-09-14T10:15:43Z|Kristiansand kate...|20763453|    external|nowiki|     Q1780675|\n",
      "|                null|                null|         null|                null|                null|            null|         null|                null|                null|          null|[495331, page]|    null|     null|          null|                null|                null|                null|                null|                null|                null|              null|                null|                null|                null|      null|                null|                null|    null|        null|  null|         null|\n",
      "|                  []|[Franskmenn, Den ...|     wikitext|                  []|2008-06-08T16:50:11Z|Duault, Isabelle|         null|[http://www.konge...|                  []|             4|          null|      nb|        0|              |Isabelle Duault e...|                null|                null|[Den_Kongelige_No...|2.965485163010495...|                  []|5.2176295652954E-7|'''Isabelle Duaul...|                  []|Isabelle Duault e...|       877|2016-01-07T13:13:09Z|     Isabelle Duault|15423889|    external|nowiki|    Q11977530|\n",
      "|                null|                null|         null|                null|                null|            null|         null|                null|                null|          null|[285838, page]|    null|     null|          null|                null|                null|                null|                null|                null|                null|              null|                null|                null|                null|      null|                null|                null|    null|        null|  null|         null|\n",
      "|[Laget kirke Karl...|[Artikler hvor om...|     wikitext|[[[58.67980999999...|2007-02-24T22:59:15Z|           false|         null|[https://www.wiki...|        [Litteratur]|            25|          null|      nb|        0|              |Laget kirke er en...|                null|[Culture.Philosop...|[Mal:Kirker_i_Aus...|7.867417648395821E-7|[[0, Laget kirkes...|              null|{{Infoboks kirke\n",
      "...|[Mal:Infoboks kir...|Laget kirke er en...|      1032|2020-05-02T04:03:13Z|         Laget kirke|20415198|    external|nowiki|    Q11982942|\n",
      "|                null|                null|         null|                null|                null|            null|         null|                null|                null|          null|[243087, page]|    null|     null|          null|                null|                null|                null|                null|                null|                null|              null|                null|                null|                null|      null|                null|                null|    null|        null|  null|         null|\n",
      "|                  []|[Artikler med off...|     wikitext|                  []|2006-12-10T21:44:38Z|           false|         null|[http://www.ferra...|  [Bilder, Bilder 2]|            10|          null|      nb|        0|              |Enzo Ferrari (200...|[Culture.Sports|3...|[Culture.Sports|3...|[2005, 28._juni, ...|2.668936646709445...| [[0, Ferrari Enzo]]| 5.590317391388E-6|'''Enzo Ferrari''...|[Mal:Wayback, Mal...|Enzo Ferrari (200...|      2719|2020-05-19T19:24:45Z|Enzo Ferrari (bil...|20504649|    external|nowiki|      Q269880|\n",
      "+--------------------+--------------------+-------------+--------------------+--------------------+----------------+-------------+--------------------+--------------------+--------------+--------------+--------+---------+--------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------+------------+------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find columns to filter on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|content_model|\n",
      "+-------------+\n",
      "|         null|\n",
      "|     wikitext|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Should one filter out null?\n",
    "df.select(\"content_model\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 25.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "548219"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df.filter(df[\"content_model\"].isNotNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 25.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "548219"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df.filter(df[\"content_model\"].isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It seems like every other row in this dataset consists of just nulls,\n",
    "# so I remove those rows\n",
    "df_not_null = df.filter(df[\"content_model\"].isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|language|\n",
      "+--------+\n",
      "|      nb|\n",
      "+--------+\n",
      "\n",
      "Wall time: 26.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# After removing the nulls, there is only one language (where previously null also showed up)\n",
    "df_not_null.select(\"language\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|        0|\n",
      "+---------+\n",
      "\n",
      "Wall time: 25.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# About namespaces https://en.wikipedia.org/wiki/Wikipedia:Namespace\n",
    "# Articles have no namespace (no prefix), we are interested in namespace 0.\n",
    "# It seems this dataset only contains the namespace we are interested in!\n",
    "df_not_null.select(\"namespace\").distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out columns\n",
    "filtered_df = df_not_null.drop(\"content_model\", \"language\", \"category\", \"coordinates\", \"defaultsort\", \\\n",
    "        \"external_link\", \"heading\", \"incoming_links\", \"namespace\", \"namespace_text\", \\\n",
    "        \"outgoing_link\", \"redirect\", \"text_bytes\", \"template\", \"wiki\", \\\n",
    "        \"wikibase_item\", \"version_type\", \"file_bits\", \"file_height\", \"file_media_type\", \\\n",
    "        \"file_resolution\", \"file_size\", \"file_text\", \"file_width\", \"index\", \\\n",
    "        \"file_mime\", \"ores_articletopic\", \"ores_articletopics\", \"score\", \"popularity_score\", \\\n",
    "        \"display_title\", \"auxiliary_text\", \"create_timestamp\", \"opening_text\", \"source_text\", \\\n",
    "        \"timestamp\", \"version\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|                text|     title|\n",
      "+--------------------+----------+\n",
      "|Kill Buljo er en ...|Kill Buljo|\n",
      "+--------------------+----------+\n",
      "\n",
      "Wall time: 25.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Seems like only one entry per article. That's good! I feared it was one per revision.\n",
    "filtered_df.filter(filtered_df[\"title\"] == \"Kill Buljo\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 25 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Kill Buljo er en norsk film fra 2008. Den er en komisk parodi på det amerikanske actioneeventyret Kill Bill, og handlingen er lagt til Finnmark. Regi er ved Tommy Wirkola og manus Stig Frode Henriksen og Tommy Wirkola. Filmen hadde premiere i mars 2007, og ble sett av 87 000 på kino i Norge. Det ble solgt over 95 000 DVD-er. Filmmusikken ble bl.a. laget av Alta-bandet Cyaneed. Kill Buljo 2 kom ut i 2013. Jompa Tormann er rollefiguren som spilles av Stig Frode Henriksen i filmen Kill Buljo. Rollefiguren dukker også opp i flere kortfilmer på DVD-en Kill Buljo: The Beginning. Jompa Tormann: Stig Frode Henriksen Pappa Buljo: Frank Arne Olsen Tampa Buljo: Martin Hykkerud Sid Wisløff: Tommy Wirkola Unni Formen: Natasha Angel Dahle Peggy Mathilassi: Linda Øverlie Nilsen Crazy Beibifeit: Ørjan Gamst Kjell Driver: John Even Pedersen Bud Light: Christian Reiertsen Lara Kofta: Merete Nordahl Mr. Handjagi: Ørjan Gamst Kato: Jørn Tore Nilsen Blow Job: Heidi Monsen Troll Tove: Eirik Junge Eliassen Sid Wisløffs far: Kristian Figenschow Mona Smurfen: Aina Timbiani Anmeldelse i Verdens Gang Anmeldelse i Bergens Tidende Anmeldelse i Nettavisen Anmeldelse i Stavanger Aftenblad Anmeldelse i Adresseavisen ^ Endring av aldersgrense på filmen Kill Buljo – the movie[død lenke], Medietilsynet, 29. mars 2007 ^ Bergensavisen – Mer «Kill Buljo» Offisielt nettsted (en) Kill Buljo på Internet Movie Database (no) Kill Buljo i Nasjonalbibliotekets filmografi (en) Kill Buljo på AllMovie (en) Kill Buljo på Turner Classic Movies (en) Kill Buljo på Rotten Tomatoes Dagbladet – Kill Buljo til utlandet Kill Buljo hos Filmweb Denne norske filmrelaterte artikkelen er foreløpig kort eller mangelfull, og du kan hjelpe Wikipedia ved å utvide den. Det finnes mer utfyllende artikkel/artikler på \\xa0.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Comparing the content in the text column to the content on the web page\n",
    "# https://no.wikipedia.org/wiki/Kill_Buljo\n",
    "filtered_df.filter(filtered_df[\"title\"] == \"Kill Buljo\").select(\"text\").collect()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems the text column contains everything in the article, so I went back and removed all columns except `text` and `title`.\n",
    "\n",
    "The text content itself could need some cleaning. There are several instances of `(en)` which looking at the web page seems to be the language of the external reference, so at least remove `(en)` and `(no)`. At one point we see `[død lenke]` which is an inline footnote, possibly a generic one. Going to the web page we find that it was created by a bot. On Wikipedia we find a web page listing [all referance template tags that can appear in running text](https://no.wikipedia.org/wiki/Mal:Trenger_referanse).\n",
    "\n",
    "Also found a [list over sentences called \"stub\"](https://no.wikipedia.org/wiki/Kategori:Stubbmaler) that can appear in the running text. Unfortunately there were 361 of them, and much more template [on the list of all tempaltes](https://no.wikipedia.org/wiki/Kategori:Maler). I tried to use the other dataset (`...general.json`) to find the text the templates produces so I could remove that, but gave up.\n",
    "\n",
    "We see that \\xa0 appears.\n",
    "\n",
    "And lastly we want to remove punctuation marks, digits and other special characters. Basically be left with only words consisting of letters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the text content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_template_reference_tags = [\"[trenger referanse]\", \"[klargjør]\", \"[hvor?]\", \"[trenger oppdatering]\", \"[død lenke]\", \"[trenger sitat]\", \"[trenger bedre kilde]\", \"[bør utdypes]\", \"[hvem?]\", \"[omstridt – diskuter]\", \"[ufullstendig referanse]\", \"[ikke i angitt kilde]\", \"[tredjepartskilde trengs]\", \"[når?]\", \"[av hvem?]\", \"[sic]\", \"[trenger sidetall]\"]\n",
    "\n",
    "# First time I understand this is a generator and not just a for loop\n",
    "# Weirdly enough, the ISO 639-3 alpha_2 codes doesn't contain \"en\"\n",
    "ext_ref_language_tags = [f\"({country.alpha_2.lower()})\" for country in pycountry.countries] + [\"(en)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_possible_template_text = []\n",
    "# It is empty because I don't know! I tried to find the templates in \n",
    "# \"Mining meta information about Wikipedia.ipynb\", but failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use RDD features to map and reduce\n",
    "# Transform from Row with title and text to just text strings, rigth away\n",
    "rdd = filtered_df.rdd.map(lambda row: row.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_strings(src_string: str, strings_to_remove: list):\n",
    "    new_string= src_string\n",
    "    for s in strings_to_remove:\n",
    "        new_string = new_string.replace(s, \"\")\n",
    "    return new_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hundene i Riga er en svensk film fra 1995 av Per Berglund med Rolf Lassgård, Björn Kjellman, Charlotte Sieling og Paul Butkevich i noen av rollene. Filmen basert seg på romanen Hundene i Riga av Henning Mankell som er den andre i serien om Kurt Wallander. En livbåt flyter i land ved den skånske kysten. I båten befinner det seg to menn som har blitt myrdet. Etterforsker Kurt Wallander fra politiet i Ystad tilkalles til plassen. Ved hjelp av politiet i Latvia blir begge mennene identifisert. For å lette utredningen ble en politimann tilkalt fra Latvia for å hjelpe til å løse saken. Men når politimannen vender tilbake til Latvia blir han myrdet. Kurt Wallander flyr til Latvia for å forsøke å finne ut hvorfor politimannen ble myrdet. (en) Hundene i Riga på Internet Movie Database (sv) Hundene i Riga i Svensk Filmdatabas (en) Hundene i Riga på Rotten Tomatoes Portal: Film',\n",
       " 'Kill Buljo er en norsk film fra 2008. Den er en komisk parodi på det amerikanske actioneeventyret Kill Bill, og handlingen er lagt til Finnmark. Regi er ved Tommy Wirkola og manus Stig Frode Henriksen og Tommy Wirkola. Filmen hadde premiere i mars 2007, og ble sett av 87 000 på kino i Norge. Det ble solgt over 95 000 DVD-er. Filmmusikken ble bl.a. laget av Alta-bandet Cyaneed. Kill Buljo 2 kom ut i 2013. Jompa Tormann er rollefiguren som spilles av Stig Frode Henriksen i filmen Kill Buljo. Rollefiguren dukker også opp i flere kortfilmer på DVD-en Kill Buljo: The Beginning. Jompa Tormann: Stig Frode Henriksen Pappa Buljo: Frank Arne Olsen Tampa Buljo: Martin Hykkerud Sid Wisløff: Tommy Wirkola Unni Formen: Natasha Angel Dahle Peggy Mathilassi: Linda Øverlie Nilsen Crazy Beibifeit: Ørjan Gamst Kjell Driver: John Even Pedersen Bud Light: Christian Reiertsen Lara Kofta: Merete Nordahl Mr. Handjagi: Ørjan Gamst Kato: Jørn Tore Nilsen Blow Job: Heidi Monsen Troll Tove: Eirik Junge Eliassen Sid Wisløffs far: Kristian Figenschow Mona Smurfen: Aina Timbiani Anmeldelse i Verdens Gang Anmeldelse i Bergens Tidende Anmeldelse i Nettavisen Anmeldelse i Stavanger Aftenblad Anmeldelse i Adresseavisen ^ Endring av aldersgrense på filmen Kill Buljo – the movie, Medietilsynet, 29. mars 2007 ^ Bergensavisen – Mer «Kill Buljo» Offisielt nettsted (en) Kill Buljo på Internet Movie Database (no) Kill Buljo i Nasjonalbibliotekets filmografi (en) Kill Buljo på AllMovie (en) Kill Buljo på Turner Classic Movies (en) Kill Buljo på Rotten Tomatoes Dagbladet – Kill Buljo til utlandet Kill Buljo hos Filmweb Denne norske filmrelaterte artikkelen er foreløpig kort eller mangelfull, og du kan hjelpe Wikipedia ved å utvide den. Det finnes mer utfyllende artikkel/artikler på \\xa0.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove possible_template_reference_tags\n",
    "removed_templates_rdd = rdd.map(lambda s: remove_strings(s, possible_template_reference_tags))\n",
    "removed_templates_rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hundene i Riga er en svensk film fra 1995 av Per Berglund med Rolf Lassgård, Björn Kjellman, Charlotte Sieling og Paul Butkevich i noen av rollene. Filmen basert seg på romanen Hundene i Riga av Henning Mankell som er den andre i serien om Kurt Wallander. En livbåt flyter i land ved den skånske kysten. I båten befinner det seg to menn som har blitt myrdet. Etterforsker Kurt Wallander fra politiet i Ystad tilkalles til plassen. Ved hjelp av politiet i Latvia blir begge mennene identifisert. For å lette utredningen ble en politimann tilkalt fra Latvia for å hjelpe til å løse saken. Men når politimannen vender tilbake til Latvia blir han myrdet. Kurt Wallander flyr til Latvia for å forsøke å finne ut hvorfor politimannen ble myrdet.  Hundene i Riga på Internet Movie Database  Hundene i Riga i Svensk Filmdatabas  Hundene i Riga på Rotten Tomatoes Portal: Film',\n",
       " 'Kill Buljo er en norsk film fra 2008. Den er en komisk parodi på det amerikanske actioneeventyret Kill Bill, og handlingen er lagt til Finnmark. Regi er ved Tommy Wirkola og manus Stig Frode Henriksen og Tommy Wirkola. Filmen hadde premiere i mars 2007, og ble sett av 87 000 på kino i Norge. Det ble solgt over 95 000 DVD-er. Filmmusikken ble bl.a. laget av Alta-bandet Cyaneed. Kill Buljo 2 kom ut i 2013. Jompa Tormann er rollefiguren som spilles av Stig Frode Henriksen i filmen Kill Buljo. Rollefiguren dukker også opp i flere kortfilmer på DVD-en Kill Buljo: The Beginning. Jompa Tormann: Stig Frode Henriksen Pappa Buljo: Frank Arne Olsen Tampa Buljo: Martin Hykkerud Sid Wisløff: Tommy Wirkola Unni Formen: Natasha Angel Dahle Peggy Mathilassi: Linda Øverlie Nilsen Crazy Beibifeit: Ørjan Gamst Kjell Driver: John Even Pedersen Bud Light: Christian Reiertsen Lara Kofta: Merete Nordahl Mr. Handjagi: Ørjan Gamst Kato: Jørn Tore Nilsen Blow Job: Heidi Monsen Troll Tove: Eirik Junge Eliassen Sid Wisløffs far: Kristian Figenschow Mona Smurfen: Aina Timbiani Anmeldelse i Verdens Gang Anmeldelse i Bergens Tidende Anmeldelse i Nettavisen Anmeldelse i Stavanger Aftenblad Anmeldelse i Adresseavisen ^ Endring av aldersgrense på filmen Kill Buljo – the movie, Medietilsynet, 29. mars 2007 ^ Bergensavisen – Mer «Kill Buljo» Offisielt nettsted  Kill Buljo på Internet Movie Database  Kill Buljo i Nasjonalbibliotekets filmografi  Kill Buljo på AllMovie  Kill Buljo på Turner Classic Movies  Kill Buljo på Rotten Tomatoes Dagbladet – Kill Buljo til utlandet Kill Buljo hos Filmweb Denne norske filmrelaterte artikkelen er foreløpig kort eller mangelfull, og du kan hjelpe Wikipedia ved å utvide den. Det finnes mer utfyllende artikkel/artikler på \\xa0.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove language tags\n",
    "removed_lang_tags_rdd = removed_templates_rdd.map(lambda s: remove_strings(s, ext_ref_language_tags))\n",
    "removed_lang_tags_rdd.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatisation\n",
    "\n",
    "I purposefully didn't [stem](https://en.wikipedia.org/wiki/Stemming) the words, since that could lead to non-existing words. E.g. `opparbeide` -> the stem `opparbeid`, `adresse` -> `adress`. The first time I got to the bottom of this notebook I found that the result contained different [inflection](https://en.wikipedia.org/wiki/Inflection) of the word \"artikkel\", \"artikkelene\", \"artikler\". Although I didn't want to stem the words, I still wanted to avoid having different inflections of the same root word.\n",
    "\n",
    "After some Googling I learned I was looking for the [lemma](https://en.wikipedia.org/wiki/Lemma_(morphology)), and finding it is called lemmatisation.\n",
    "\n",
    "I just decided to go with the package spaCy since had a simple API and does [POS tagging](https://en.wikipedia.org/wiki/Part-of-speech_tagging) automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run the following line once. The leading exclamation mark means it is a terminal command\n",
    "# !python -m spacy download nb_core_news_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got problems with memory tryng to call the above function with PySpark (using map). You can read about some problems [in this blog post](https://haridas.in/run-spacy-jobs-on-apache-spark.html). After some trying and failing I decided to simply run spaCy with plain Python. \n",
    "\n",
    "Since I don't have enough RAM to load all data and don't think it is possibly to lazily iterate over an RDD, I must dump data to storage at this point. Note, if you get memory error while running `saveAsTextFile` method on the RDD on Windows, [see this Stack Overflow answer](https://stackoverflow.com/questions/40764807/null-entry-in-command-string-exception-in-saveastextfile-on-pyspark/40958969). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o101.saveAsTextFile.\n: org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/E:/workspace3/online-alias/words/temp1 already exists\r\n\tat org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)\r\n\tat org.apache.spark.internal.io.HadoopMapRedWriteConfigUtil.assertConf(SparkHadoopWriter.scala:289)\r\n\tat org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:71)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1090)\r\n\tat org.apache.spark.rdd.PairRDDFunctions$$Lambda$3167/000000000000000000.apply$mcV$sp(Unknown Source)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:388)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1088)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1061)\r\n\tat org.apache.spark.rdd.PairRDDFunctions$$Lambda$3165/000000000000000000.apply$mcV$sp(Unknown Source)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:388)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1026)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1008)\r\n\tat org.apache.spark.rdd.PairRDDFunctions$$Lambda$3164/000000000000000000.apply$mcV$sp(Unknown Source)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:388)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1007)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$2(PairRDDFunctions.scala:964)\r\n\tat org.apache.spark.rdd.PairRDDFunctions$$Lambda$3163/000000000000000000.apply$mcV$sp(Unknown Source)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:388)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:962)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$saveAsTextFile$2(RDD.scala:1552)\r\n\tat org.apache.spark.rdd.RDD$$Lambda$3161/000000000000000000.apply$mcV$sp(Unknown Source)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:388)\r\n\tat org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1552)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$saveAsTextFile$1(RDD.scala:1538)\r\n\tat org.apache.spark.rdd.RDD$$Lambda$3160/000000000000000000.apply$mcV$sp(Unknown Source)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:388)\r\n\tat org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1538)\r\n\tat org.apache.spark.api.java.JavaRDDLike.saveAsTextFile(JavaRDDLike.scala:550)\r\n\tat org.apache.spark.api.java.JavaRDDLike.saveAsTextFile$(JavaRDDLike.scala:549)\r\n\tat org.apache.spark.api.java.AbstractJavaRDDLike.saveAsTextFile(JavaRDDLike.scala:45)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.base/java.lang.Thread.run(Thread.java:836)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32me:\\workspace3\\online-alias\\words\\.venv\\lib\\site-packages\\pyspark\\rdd.py\u001b[0m in \u001b[0;36msaveAsTextFile\u001b[1;34m(self, path, compressionCodecClass)\u001b[0m\n\u001b[0;32m   1654\u001b[0m             \u001b[0mkeyed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaveAsTextFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompressionCodec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1655\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1656\u001b[1;33m             \u001b[0mkeyed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaveAsTextFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1658\u001b[0m     \u001b[1;31m# Pair functions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\workspace3\\online-alias\\words\\.venv\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1304\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\workspace3\\online-alias\\words\\.venv\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\workspace3\\online-alias\\words\\.venv\\lib\\site-packages\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                 raise Py4JJavaError(\n\u001b[0m\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o101.saveAsTextFile.\n: org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/E:/workspace3/online-alias/words/temp1 already exists\r\n\tat org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)\r\n\tat org.apache.spark.internal.io.HadoopMapRedWriteConfigUtil.assertConf(SparkHadoopWriter.scala:289)\r\n\tat org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:71)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1090)\r\n\tat org.apache.spark.rdd.PairRDDFunctions$$Lambda$3167/000000000000000000.apply$mcV$sp(Unknown Source)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:388)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1088)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1061)\r\n\tat org.apache.spark.rdd.PairRDDFunctions$$Lambda$3165/000000000000000000.apply$mcV$sp(Unknown Source)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:388)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1026)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1008)\r\n\tat org.apache.spark.rdd.PairRDDFunctions$$Lambda$3164/000000000000000000.apply$mcV$sp(Unknown Source)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:388)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1007)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$2(PairRDDFunctions.scala:964)\r\n\tat org.apache.spark.rdd.PairRDDFunctions$$Lambda$3163/000000000000000000.apply$mcV$sp(Unknown Source)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:388)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:962)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$saveAsTextFile$2(RDD.scala:1552)\r\n\tat org.apache.spark.rdd.RDD$$Lambda$3161/000000000000000000.apply$mcV$sp(Unknown Source)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:388)\r\n\tat org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1552)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$saveAsTextFile$1(RDD.scala:1538)\r\n\tat org.apache.spark.rdd.RDD$$Lambda$3160/000000000000000000.apply$mcV$sp(Unknown Source)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:388)\r\n\tat org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1538)\r\n\tat org.apache.spark.api.java.JavaRDDLike.saveAsTextFile(JavaRDDLike.scala:550)\r\n\tat org.apache.spark.api.java.JavaRDDLike.saveAsTextFile$(JavaRDDLike.scala:549)\r\n\tat org.apache.spark.api.java.AbstractJavaRDDLike.saveAsTextFile(JavaRDDLike.scala:45)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.base/java.lang.Thread.run(Thread.java:836)\r\n"
     ]
    }
   ],
   "source": [
    "# Uncomment to dump\n",
    "# %%time\n",
    "# removed_lang_tags_rdd.saveAsTextFile(\"temp1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run lemmatisation in batches and write to file\n",
    "\n",
    "If you already have run the cell above once, you can start from this cell later!\n",
    "\n",
    "> Remember to run the first cell with the imports, though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nb_core_news_lg\n",
    "nlp = nb_core_news_lg.load()\n",
    "\n",
    "def lemmatize_documents(src_documents: list):\n",
    "    docs = nlp.pipe(texts=src_documents)\n",
    "    new_documents = []\n",
    "    for doc in docs:\n",
    "        new_string = \"\"\n",
    "        for token in doc:\n",
    "            if (token.lemma_ != \"-PRON-\"):\n",
    "                new_string += f\" {token.lemma_}\"\n",
    "            else:\n",
    "                # spacy returns the lemma \"-PRON-\" for pronouns, and we don't want that,\n",
    "                # in that case we return the original word istead\n",
    "                new_string += f\" {token}\"\n",
    "        new_documents.append(new_string)\n",
    "    return new_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN EACH TIME\n",
    "# This cell takes hours to execute.\n",
    "# Uncomment all the following lines to run:\n",
    "# %%time\n",
    "# with open(\"./out/lemmatised_wikipedia.txt\", \"a\", encoding=\"utf-8\") as f_out:\n",
    "#     temp_folder = \"./temp1\"\n",
    "#     directory = os.fsencode(temp_folder)\n",
    "    \n",
    "#     for file in os.listdir(directory):\n",
    "#         starttime = time.time()\n",
    "#         filename = os.fsdecode(file)\n",
    "#         if (filename.endswith(\".crc\") or filename == \"_SUCCESS\"):\n",
    "#             continue\n",
    "#         f_in = open(f\"{temp_folder}/{filename}\", encoding=\"utf-8\")\n",
    "#         print(f\"START processing {filename}\")\n",
    "#         # Read file in parts to avoid yet another memory problem:\n",
    "#         # MemoryError: Unable to allocate 2.08 GiB for an array with shape (546345, 1024) and data type float32\n",
    "#         # If there are too many lines in combinations with large articles, I don't have enough RAM (8GB)\n",
    "#         docs = []\n",
    "#         num_lines = 0\n",
    "#         print(\"0 lines processed\", end='\\r')\n",
    "#         batch_size = 500\n",
    "#         if (\"part-00032\" in filename or \"part-00035\" in filename \\\n",
    "#             or \"part-00036\" in filename or \"part-00037\" in filename \\\n",
    "#             or \"part-00038\" in filename or \"part-00041\" in filename \\\n",
    "#             or \"part-00042\" in filename or \"part-00043\" in filename):\n",
    "#             batch_size = 200\n",
    "#         for line in f_in:\n",
    "#             docs.append(line)\n",
    "#             if (len(docs) == batch_size):\n",
    "#                 try:\n",
    "#                     lemmatised_docs = lemmatize_documents(docs)\n",
    "#                     f_out.writelines(lemmatised_docs)\n",
    "#                     num_lines += batch_size\n",
    "#                     docs = []\n",
    "#                 except MemoryError:\n",
    "#                     print(f\"Error happened between lines {num_lines} and {num_lines + batch_size}\")\n",
    "#                     raise\n",
    "#                 print(f\"{num_lines} lines processed\", end='\\r')\n",
    "#         if (len(docs) > 0):\n",
    "#             lemmatised_docs = lemmatize_documents(docs)\n",
    "#             f_out.writelines(lemmatised_docs)\n",
    "#             print(f\"{num_lines} lines processed\", end='\\r')\n",
    "#             num_lines += len(docs)\n",
    "#         f_in.close()\n",
    "#         print(f\"END processing {filename}. It had {num_lines} lines. It took {round(time.time() - starttime)} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load lemmatised file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' hund i Riga er en svensk film fra 1995 av Per Berglund med Rolf Lassgård , Björn Kjellman , Charlotte Sieling og Paul Butkevich i noen av rolle . film basere seg på roman hund i Riga av Henning Mankell som er den andre i serie om Kurt Wallander . en livbåt flyte i land ved den skånsk kyst . i båt befinne det seg to mann som har blitt myrde . etterforsker Kurt Wallander fra politi i Ystad tilkalle til plass . ved hjelp av politi i Latvia bli begge mann identifisere . for å leite utredning bli en politimann tilkalle fra Latvia for å hjelpe til å løse sake . men når politimann vende tilbake til Latvia blir han myrde . Kurt Wallander fly til Latvia for å forsøke å finne ut hvorfor politimann ble myrde .   hund i Riga på Internet Movie Database   hund i Riga i Svensk Filmdatabas   hund i Riga på Rotten Tomatoes Portal : film ',\n",
       " ' Kill Buljo er en norsk film fra 2008. Den er en komisk parodi på det amerikansk actioneeventyr Kill Bill , og handling er legge til Finnmark . regi er ved Tommy Wirkola og manus Stig Frode Henriksen og Tommy Wirkola . film ha premiere i mars 2007 , og ble sette av 87 000 på kino i Norge . Det ble selge over 95 000 dvd . filmmusikk ble bl.a. lage av alta-band Cyaneed . Kill Buljo 2 komme ut i 2013. jompe Tormann er rollefigur som spille av Stig Frode Henriksen i film Kill Buljo . rollefigur dukke også opp i mange kortfilm på dvd Kill Buljo : The Beginning . jompe Tormann : Stig Frode Henriksen pappa Buljo : Frank Arne Olsen Tampa Buljo : Martin Hykkerud Sid Wisløff : Tommy Wirkola Unni Formen : Natasha Angel Dahle Peggy Mathilassi : Linda Øverlie Nilsen Crazy Beibifeit : Ørjan Gamst Kjell Driver : John Even Pedersen Bud Light : Christian Reiertsen Lara Kofta : Merete Nordahl Mr. Handjagi : Ørjan Gamst Kato : Jørn Tore Nilsen Blow Job : Heidi Monsen Troll Tove : Eirik Junge Eliassen Sid Wisløffs far : Kristian Figenschow Mona Smurfen : Aina Timbiani anmeldelse i Verdens gang anmeldelse i Bergens Tidende anmeldelse i Nettavisen anmeldelse i Stavanger Aftenblad anmeldelse i Adresseavisen ^ endring av aldersgrense på film Kill Buljo – the movie , Medietilsynet , 29. mars 2007 ^ Bergensavisen – mye « Kill Buljo » offisiell nettsted   Kill Buljo på Internet Movie Database   Kill Buljo i Nasjonalbibliotekets filmografi   Kill Buljo på AllMovie   Kill Buljo på Turner Classic Movies   Kill Buljo på Rotten Tomatoes Dagbladet – Kill Buljo til utland Kill Buljo hos Filmweb denne norsk filmrelatert artikkel er foreløpig kort eller mangelfull , og du kan hjelpe Wikipedia ved å utvide den . Det finnes mye utfylle artikkel/artikle på    . ']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatised_df = spark.read.csv(\"./out/lemmatised_wikipedia.txt\", sep=\"╚\")\n",
    "# The Row is called _c0 since I didn't specify any columns\n",
    "lemmatised_rdd = lemmatised_df.rdd.map(lambda row: row._c0)\n",
    "lemmatised_rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_letter_words_and_chars(src_string: str):\n",
    "    whitelist = set('abcdefghijklmnopqrstuvwxyzæøå ABCDEFGHIJKLMNOPQRSTUVWXYZÆØÅ')\n",
    "    new_string = \"\"\n",
    "    for char in src_string:\n",
    "        if char in whitelist:\n",
    "            new_string = new_string + char\n",
    "        else:\n",
    "            new_string = new_string + \" \"\n",
    "    return new_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' hund i Riga er en svensk film fra      av Per Berglund med Rolf Lassgård   Bj rn Kjellman   Charlotte Sieling og Paul Butkevich i noen av rolle   film basere seg på roman hund i Riga av Henning Mankell som er den andre i serie om Kurt Wallander   en livbåt flyte i land ved den skånsk kyst   i båt befinne det seg to mann som har blitt myrde   etterforsker Kurt Wallander fra politi i Ystad tilkalle til plass   ved hjelp av politi i Latvia bli begge mann identifisere   for å leite utredning bli en politimann tilkalle fra Latvia for å hjelpe til å løse sake   men når politimann vende tilbake til Latvia blir han myrde   Kurt Wallander fly til Latvia for å forsøke å finne ut hvorfor politimann ble myrde     hund i Riga på Internet Movie Database   hund i Riga i Svensk Filmdatabas   hund i Riga på Rotten Tomatoes Portal   film ',\n",
       " ' Kill Buljo er en norsk film fra       Den er en komisk parodi på det amerikansk actioneeventyr Kill Bill   og handling er legge til Finnmark   regi er ved Tommy Wirkola og manus Stig Frode Henriksen og Tommy Wirkola   film ha premiere i mars        og ble sette av        på kino i Norge   Det ble selge over        dvd   filmmusikk ble bl a  lage av alta band Cyaneed   Kill Buljo   komme ut i       jompe Tormann er rollefigur som spille av Stig Frode Henriksen i film Kill Buljo   rollefigur dukke også opp i mange kortfilm på dvd Kill Buljo   The Beginning   jompe Tormann   Stig Frode Henriksen pappa Buljo   Frank Arne Olsen Tampa Buljo   Martin Hykkerud Sid Wisløff   Tommy Wirkola Unni Formen   Natasha Angel Dahle Peggy Mathilassi   Linda Øverlie Nilsen Crazy Beibifeit   Ørjan Gamst Kjell Driver   John Even Pedersen Bud Light   Christian Reiertsen Lara Kofta   Merete Nordahl Mr  Handjagi   Ørjan Gamst Kato   Jørn Tore Nilsen Blow Job   Heidi Monsen Troll Tove   Eirik Junge Eliassen Sid Wisløffs far   Kristian Figenschow Mona Smurfen   Aina Timbiani anmeldelse i Verdens gang anmeldelse i Bergens Tidende anmeldelse i Nettavisen anmeldelse i Stavanger Aftenblad anmeldelse i Adresseavisen   endring av aldersgrense på film Kill Buljo   the movie   Medietilsynet       mars        Bergensavisen   mye   Kill Buljo   offisiell nettsted   Kill Buljo på Internet Movie Database   Kill Buljo i Nasjonalbibliotekets filmografi   Kill Buljo på AllMovie   Kill Buljo på Turner Classic Movies   Kill Buljo på Rotten Tomatoes Dagbladet   Kill Buljo til utland Kill Buljo hos Filmweb denne norsk filmrelatert artikkel er foreløpig kort eller mangelfull   og du kan hjelpe Wikipedia ved å utvide den   Det finnes mye utfylle artikkel artikle på      ']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_letters_rdd = lemmatised_rdd.map(lambda s: remove_non_letter_words_and_chars(s))\n",
    "only_letters_rdd.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_lowercase_if_not_acronym(src_string: str):\n",
    "    for letter in src_string:\n",
    "        if letter.islower():\n",
    "            return src_string.lower()\n",
    "    return src_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 968 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['hund',\n",
       " 'riga',\n",
       " 'er',\n",
       " 'en',\n",
       " 'svensk',\n",
       " 'film',\n",
       " 'fra',\n",
       " 'av',\n",
       " 'per',\n",
       " 'berglund',\n",
       " 'med',\n",
       " 'rolf',\n",
       " 'lassgård',\n",
       " 'bj',\n",
       " 'rn',\n",
       " 'kjellman',\n",
       " 'charlotte',\n",
       " 'sieling',\n",
       " 'og',\n",
       " 'paul']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Convert string to list of lowercase words larger with two or more characters\n",
    "words_rdd = only_letters_rdd \\\n",
    "    .flatMap(lambda s: s.split(\" \")) \\\n",
    "    .filter(lambda word: len(word) > 1) \\\n",
    "    .map(lambda word: convert_to_lowercase_if_not_acronym(word))\n",
    "words_rdd.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['og', 'i', 'jeg', 'det', 'at', 'en', 'et', 'den', 'til', 'er']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of stopwords taken from http://snowball.tartarus.org/algorithms/norwegian/stop.txt\n",
    "stopwords = []\n",
    "with open(\"./norwegian_stopwords.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        strings = line.split(\"|\")\n",
    "        potential_stopword = strings[0].strip()\n",
    "        if (not potential_stopword == \"\"):\n",
    "            stopwords.append(potential_stopword)\n",
    "\n",
    "# Remove English stopwords as well since I noticed \"the\", \"in\", and \"of\" in the top 20\n",
    "# Inspired by the Google History stopword list found at https://www.ranks.nl/stopwords\n",
    "english_stopwords = [\"I\", \"a\", \"an\", \"are\", \"as\", \"at\", \"by\", \"com\", \"for\", \"from\", \"how\", \"in\", \"it\", \"of\", \"on\", \"that\", \"the\", \"this\", \"was\", \"what\", \"when\", \"where\", \"who\", \"will\", \"with\", \"www\"]\n",
    "stopwords = stopwords + english_stopwords\n",
    "stopwords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_word_in_list(src_word: str, list_of_words: list):\n",
    "    if (src_word in list_of_words):\n",
    "        return \"\"\n",
    "    else:\n",
    "        return src_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 989 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['hund',\n",
       " 'riga',\n",
       " 'svensk',\n",
       " 'film',\n",
       " 'per',\n",
       " 'berglund',\n",
       " 'rolf',\n",
       " 'lassgård',\n",
       " 'bj',\n",
       " 'rn',\n",
       " 'kjellman',\n",
       " 'charlotte',\n",
       " 'sieling',\n",
       " 'paul',\n",
       " 'butkevich',\n",
       " 'rolle',\n",
       " 'film',\n",
       " 'basere',\n",
       " 'roman',\n",
       " 'hund']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Remove all stop-words\n",
    "no_stopwords_rdd = words_rdd \\\n",
    "    .map(lambda word: remove_word_in_list(word, stopwords)) \\\n",
    "    .filter(lambda word: word != \"\")\n",
    "no_stopwords_rdd.take(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mining!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11min 50s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('besøke', 532440),\n",
       " ('norsk', 310814),\n",
       " ('mye', 297176),\n",
       " ('annen', 295609),\n",
       " ('under', 292780),\n",
       " ('to', 271410),\n",
       " ('artikkel', 243534),\n",
       " ('få', 241530),\n",
       " ('hos', 219905),\n",
       " ('år', 217310),\n",
       " ('stor', 217127),\n",
       " ('føde', 214054),\n",
       " ('første', 212349),\n",
       " ('and', 206316),\n",
       " ('oktober', 191805),\n",
       " ('komme', 188093),\n",
       " ('ta', 163825),\n",
       " ('arkivere', 157604),\n",
       " ('finnes', 156167),\n",
       " ('navn', 155230)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Finding the most popular words\n",
    "\n",
    "ranked_words_rdd = no_stopwords_rdd.map(lambda word: (word, 1)) \\\n",
    "    .reduceByKey(add) \\\n",
    "    .sortBy(lambda x: x[1], ascending=False)\n",
    "\n",
    "endTime = time.time()\n",
    "ranked_words_rdd.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "final_words_list = ranked_words_rdd.map(lambda t: t[0]).take(1000)\n",
    "with open(\"./out/wikipedia_words2.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for word in final_words_list:\n",
    "        f.write(f\"{word}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finished :D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}